---
title: 'Кластерный анализ'
date: 'July 4-5, 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
---

Поставим пакет Томаса:
```{r, eval=FALSE}
devtools::install_github('thomasp85/patchwork')
```

Подключим необходимые пакеты

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных

library(cluster) # кластерный анализ
library(factoextra) # визуализации kmeans, pca
library(dendextend) # визуализация дендрограмм

library(corrplot) # визуализация корреляций

library(broom) # метла превращает результаты оценивания моделей в таблички

library(naniar) # визуализация пропущенных значений
library(visdat) # визуализация пропущенных значений

library(patchwork) # удобное расположение графиков рядом
library(factoextra) # визуализации kmeans, pca
library(corrplot) # визуализация корреляций
```



# Кластеризация k-means

Возьмём микро данные по странам мира, которые подготовлены в SPSS.
Загрузим их и посмотрим описательные статистики.

```{r}
country <- import('C:/Users/ASUS/Desktop/r_course/data/Macro_2.sav')
skim(country)
```

Отмасштабируем данные с помощью встроенной функции `scale()`.
Поскольку она может работать только с числами, первый столбец `Country` ей передавать не нужно.
Результат сохраним в таблице `country_stand`.


```{r}
country_stand <- mutate_if(country, is.numeric, ~ as.vector(scale(.)))
skim(country_stand)
```

Дополнение в виде функции `as.vector` нужно потому, что функция `scale` возвращает матрицу,
а каждый столбец должен быть вектором :)


Выполним кластеризацию методом k-средних с помощью функции `kmeans`.
Название страны не используется для кластеризации, но нужно для меток на графиках.
Поэтому уберем столбец `Country` из набора данных и превратим его в метки строк.

В качестве аргументов укажем отмасштабированные данные `country_no_country` и количество кластеров `centers`.
Пока мы не знаем, как выбирать оптимальное количество кластеров, поэтому предположим, что их три.
Сохраним результат этого действия в список `k_means_country`.

```{r}
country_no_country <- country_stand %>% column_to_rownames(var = 'Country')
k_means_country <- kmeans(country_no_country, centers = 3)
k_means_country
```

Посмотрим на содержимое списка `k_means_country` командой `attributes()`.
```{r}
attributes(k_means_country)
```
Посмотрим, например, на координаты центра кластеров или количество объектов в каждом из них.

```{r}
k_means_country$centers
k_means_country$cluster
k_means_country$size
```

Другой способ структурировать вывод `kmeans` — использовать команду `tidy` из пакета `broom`.

```{r}
tidy(k_means_country)
```

Первые девять неназванных переменных — центры кластеров по каждой переменной.


Визуализируем результаты.

Для этого будем использовать команду `fviz_cluster()` из пакета `factoextra`.
Её аргументы — результат кластеризации `k_means_country`,
исходные данные и ещё куча настроек вроде размера точек и цвета наблюдений-выбросов.
Мы только попросим выделять цветом кластеры по их границам и укажем аргумент `ellipse.type = 'convex'`.

```{r}
fviz_cluster(object = k_means_country, data = country_no_country,
             ellipse.type = 'convex')
```

Кластеры достаточно хорошо различимы. Пересечения незначительные.


Предположим, что число кластеров - 2

```{r}
country_no_country <- country_stand %>% column_to_rownames(var = 'Country')
k_means_country <- kmeans(country_no_country, centers = 2)
k_means_country
```


Посмотрим на содержимое списка `k_means_country` командой `attributes()`.
```{r}
attributes(k_means_country)
```
Посмотрим, например, на координаты центра кластеров или количество объектов в каждом из них.

```{r}
k_means_country$centers
k_means_country$cluster
k_means_country$size
```

Другой способ структурировать вывод `kmeans` — использовать команду `tidy` из пакета `broom`.

```{r}
tidy(k_means_country)
```

Первые девять неназванных переменных — центры кластеров по каждой переменной.


Визуализируем результаты.
Для этого будем использовать команду `fviz_cluster()` из пакета `factoextra`.
Её аргументы — результат кластеризации `k_means_country`,
исходные данные и ещё куча настроек вроде размера точек и цвета наблюдений-выбросов.
Мы только попросим выделять цветом кластеры по их границам и укажем аргумент `ellipse.type = 'convex'`.

```{r}
fviz_cluster(object = k_means_country, data = country_no_country,
             ellipse.type = 'convex')
```

Кластеры хорошо различимы 


Cколько кластеров оптимально?
Один из способов сделать это — воспользоваться командой `fviz_nbclust` из пакета `factoextra`.


```{r}
g1 <- fviz_nbclust(country_no_country, kmeans, method = 'wss') +
  labs(subtitle = 'Elbow method')
g1

g2 <- fviz_nbclust(country_no_country, kmeans, method = 'silhouette') +
  labs(subtitle = 'Silhouette method')
g2

g3 <- fviz_nbclust(country_no_country, kmeans, method = 'gap_stat') +
  labs(subtitle = 'Gap statistic method')
g3
```

Анализ результатов помогает увидеть, что оптимальное число кластеров может быть 3 или 6 (внршины на графике). 6 - это слишком большое число кластеров, которое отличается незначительными нюансами, поэтому целесообразно выделить 3 клатера.

С помощью хитрого пакета Томаса располагать графики легко!
Попробуйте!

```{r}
(g1 + g2) / g3
g1 + g2 + g3
g1 + (g2 / g3)
```

Метки кластерам легко добавить к исходным данным:

```{r}
country_plus <- mutate(country, cluster = k_means_country$cluster)
glimpse(country_plus)
```

# Иерархическая кластеризация

Другой способ разбить данные на группы — иерархическая кластеризация.
Но, в отличие от метода k-средних, она работает с матрицей расстояний,
поэтому первым делом посчитаем её!
Для этого будем использовать функцию `dist()`.
Передадим ей стандартизированные данные и укажем явно, как считать расстояния с помощью аргумента `method`.


```{r}
country_dist <- dist(country_no_country, method = 'euclidian')
```

Визуализируем расстояния с помощью команды `fviz_dist` из пакета `factoextra`.

```{r}
fviz_dist(country_dist)
```

Полученную матрицу расстояний можно передадать функции `hclust()`, которая кластеризует данные.
Однако в пакете `factoextra` есть функция `hcut()`, которая работает с исходными данными.
Будем использовать её и попросим выделить 4 кластера в аргументе `k`.


```{r}
country_hcl <- hcut(country_no_country, k = 4)
```

С помощью функции `fviz_dend` визуализируем результат кластеризации.
Укажем несколько аргументов, чтобы сделать дендрограмму красивее,
(полный перечень можно посмотреть в справке).
Согласно построенным дендрограммам наилучшее разбиение объектов на 4 кластера.

```{r}
fviz_dend(country_hcl,
          cex = 0.5, # размер подписи
          color_labels_by_k = TRUE) # цвет подписей по группам
```

Выявленные кластеры можно добавить к исходным данным!
```{r}
country_plus2 <- mutate(country, cluster = country_hcl$cluster)
glimpse(country_plus2)
```


Иерархичская кластеризация полезна и для визуализаций корреляций.
Если в функции `corrplot()` из одноимённого пакета указать аргумента `order = hclust`,
то мы получим сгруппированные по кластерам переменные.
Для красоты добавим ещё один аргумент — `addrect = 4`.
Он обведёт прямоугольниками указанное число кластеров.

```{r}
country_cor <- cor(country_no_country)
corrplot(country_cor, order = 'hclust', addrect = 4)
```

# МЕТОД ГЛАВНЫХ КОМПОНЕНТ

Примените метод главных компонент к набору данных о странах и затем визуализируем результат в осях первых двух главных компонент.

```{r}
country_pca <- prcomp(country_no_country)
country_pca 
```

```{r}
country_pca$sdev
```


Посмотрим, что лежит в списке
```{r}
attributes(country_pca)
```

Главные компоненты лежат в матрице country_pca$x
Посмотрим на первую ГК

```{r}
country_pca$x[, 1]
```

Выборочные стандартные отклоненения лежат в векторе country_pca$sdev
```{r}
country_pca$sdev
```

Матрица country_pca$rotation содержит веса, с которыми исходные переменные входят в ГК.
Ддя примера - В первой ГК лежат исходные переменные с весами


Визуализируем исходные данные на осях ГК.
Для этого необходима функция  fviz_pca_ind() из пакета factoextra.
Рисовать будем country_pca, а аргумент repel = TRUE укажем для того, чтобы подписи на графике не перекрывали друг друга

```{r}
fviz_pca_ind(country_pca, repel = TRUE)
```

Первая главная компонента смогла объяснить только 36.9% разброса даныых, вторая - 29. Таким образом, на первые две ГК приходится 65,9% вариации исходного признакового пространства.

Взглянем на все выделенные ГК

```{r}
fviz_pca_biplot(country_pca, geom.ind = 'point')
```

Визуализируйте вклад каждой переменной в первую главную компоненту.

```{r}
fviz_contrib(country_pca, choice = 'var', axes = 1)
```
Таким образом, максимальный вклад в превую ГК у пеерменных GDP, Life. Их вклад  в первую главную компоненту можно считать значительным. 

Визуализируйте вклад каждой переменной во вторую главную компоненту.

```{r}
fviz_contrib(country_pca, choice = 'var', axes = 2)
```
Таким образом, максимальный вклад во вторую ГК у пеерменных Inflation, Unemployment. Их вклад  во вторую главную компоненту можно считать значительным. 



Нарисуем проекции исходных переменных в осях первых двух главных компонент. 
Функции `fviz_pca_biplot` передадим аргумент, который делает подписи аккуратными.
```{r}
fviz_pca_biplot(country_pca, geom.ind = 'point', habillage = country$Country, repel = TRUE)
```

Визуализируйте процент разброса, который объясняет каждая главная компонента и добавим эти значения на график.

```{r}
fviz_eig(country_pca, addlabels = TRUE)
```
Первая главная компонента смогла объяснить только 36.9% разброса даныых, вторая - 29%, на третью ГК приходится 16.6% вариации признакового пространства. На первые три ГК приходится 85,5% вариации исходного признакового пространства.



Ура! :)
