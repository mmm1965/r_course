---
title: 'Логистическя регрессия'
date: 'Июль 7-8, 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
---

Настройка глобальных опций отчёта:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(Ecdat) # много-много разных наборов данных
library(ISLR) # ещё данные
library(sandwich) # оценка Var для гетероскедастичности
library(caret) # пакет для подбора параметров разных моделей
library(FFTrees) # быстрые деревья
library(margins) # для подсчёта предельных эффектов
library(rpart.plot) # для картинок деревьев
library(plotROC) # визуализация ROC-кривой
library(ggeffects) # графики для предельных эффектов
library(MLmetrics) # метрики качества
```


Импортируем набор данных по респондентам и посмотрим на него :)

```{r}
ob <- import('C:/Users/ASUS/Desktop/r_course/data/obsl_1.sav')
skim(ob)
glimpse(ob)
```

Целевая переменная — Наличие персонального компьютера RPC (1-да, 0 – нет)
Остальные переменные — характеристики финансового положения респондента и условий его проживания.

Объявим качественные переменные факторными
```{r}
ob_fct <-ob %>%
 mutate_at(vars(FINPOL, RPC), factor)
```

Прологарифмируем основные денежные показатели

```{r}
ob$lnDOXODSN <- log(ob$DOXODSN)
```

```{r}
ob$lnUSLUG <- log(ob$USLUG)
```

```{r}
ob$lnNALOG <- log(ob$NALOG)
```

```{r}
ob$lnOBPL <- log(ob$OBPL)
```

```{r}
skim(ob)
glimpse(ob)
```

Разделим выборку на две части, обучающую и тестовую.
По тестовой мы сможем оценить качество прогнозов нашей модели.

Разбиение выборки на две части — это случаная операция,
поэтому зададим на удачу зерно генератора случайных чисел.

Создадим вектор `train_rows` с номерами строк для обучающей части.

```{r}
set.seed(777)
train_rows <- createDataPartition(ob_fct$RPC, p = 0.8, list = FALSE)
train_rows
```

Разделим выборку согласно вектору `train_rows`:

```{r}
ob_train <- ob_fct[train_rows, ]
ob_test <- ob_fct[-train_rows, ]
glimpse(ob_fct)
```


# Логистическая регрессия

С помощью метода максимального правдоподобия оценивается модель

\[
y_i =
\begin{cases}
1, \text{ если } y^*_i \geq 0; \\
0, \text{ иначе.}
\end{cases}
\]

\[
y_i^* = \beta_1 + \beta_2 x_i + \beta_3 z_i + u_i,
\]
где $u_i$ имеет специальное логистическое распределение.

Также модель можно записать в виде:

\[
\frac{\ln P(y_i = 1)}{\ln P(y_i = 0)} = \beta_1 + \beta_2 x_i + \beta_3 z_i
\]


Реализуем логистическую регрессию с помощью функции `glm`.
Передадим ей набор данных `ob_train`, формулу и укажем специалный аргумент `family = binomial(link = 'logit')`.
Сохраним результаты оценивания в переменную `ob_lmodel` и посмотрим на них.

1
```{r}
ob_lmodel_glm <- glm(data = ob_train, RPC ~ DOXODSN + USLUG + NALOG + OBPL + POTRAS, family = binomial(link = 'logit'))
summary(ob_lmodel_glm)
```
AIC: 1106.3. Все переменные кроме USLUG, DOXODSN значимые.

2. Исключим переменную DOXODSN и построим новую модель
```{r}
ob_lmodel_glm <- glm(data = ob_train, RPC ~ USLUG + NALOG + OBPL + POTRAS, family = binomial(link = 'logit'))
summary(ob_lmodel_glm)
```


3. Исключим переменную USLUG и построим новую модель
```{r}
ob_lmodel_glm <- glm(data = ob_train, RPC ~ NALOG + OBPL + POTRAS, family = binomial(link = 'logit'))
summary(ob_lmodel_glm)
```

Коэффициенты модели значимы на уровне значимости $\alpha = 0.01$?
AIC: 1103.7, что немного ниже, чем у первой и второй моделей.

Лучше использовать третью модель

Чтобы найти предельные эффекты, воспользуемся функцией `margins` из одноимённого пакета.
Выведем результаты командой `summary()`.

```{r}
ob_margins <- margins(ob_lmodel_glm)
summary(ob_margins)
```
Все предельные эффекты значимые.

По умолчанию считается средний предельный эффект.
Если нужно подсчитать предельный эффект для конкретного наблюдения,
например, для среднего, то можно воспользоваться опцией `at`.

Предельные эффекты тоже можно визуализировать!
Эта функция реализована в пакете `ggeffects` и называетя `ggpredict`.
Ей нужно передать оценённую модель и указать переменные для визуализации в аргументе `terms`.

```{r, eval=FALSE}
pred_ob_vis <- ggpredict(ob_lmodel_glm, terms = c('DOXODSN', 'RPC'))
pred_ob_vis <- plot(pred_ob_vis)
```

Оценивать логистическую модель также можно с помощью пакета `caret`.

```{r}
ob_lmodel <- train(data = ob_train, RPC ~ NALOG + OBPL + POTRAS, family = binomial(link = 'logit'), method = 'glm')
summary(ob_lmodel)
```
В результате получили аналогичный результат.

Посторим прогнозы модели для тестовых данных `ob_test`.
Для этого будем использовать функцию `predict`, которой передадим оценённую модель `ob_lmodel`.
В переменной `ob_predz` уже будут лежать предсказанные классы.
Чтобы получить их вероятности, нужно добавить аргумент `type = 'prob'`.

```{r}
ob_pred <- predict(ob_lmodel, newdata = ob_test)
head(ob_pred)

ob_prob <- predict(ob_lmodel, newdata = ob_test, type = 'prob')
head(ob_prob)
```

Посмотрим на матрицу ошибок чтобы узнать, насколько хорошую модель мы оценили.
Для этого будем использовть функцию `confusionMatrix` из пакета `caret`.
В качестве аргумента `data` нужно указать предсказанные значения, а в `reference` — правильные ответы.

```{r}
confusionMatrix(data = ob_pred, reference = ob_test$RPC)
```
В редсказании нулей ошибки существенно выше, чем в предсказании единиц.

Чтобы получичть и другие метрики качества для нашей модели, будем использовать функции `twoClassSummary()` и `prSummary()`.
Первая возвращает значения ROC, специфичности и чувствительности.

Чувствительность (полнота) показывает долю правильно распознанных объектов отрицательного класса.
\[
TPR = TP / (TP + FN) = recall = sensitivity
\]

Специфичность показывает долю правильно распознанных объектов положительного класса.
\[
FPR = FP / (FP + TN) = 1 - specificity
\]

ROC — это площадь под кривой, построенной в осях доли правильных положительных ответов и
доли неправильных положительных ответов в зависимости от значения порога для попадания
в положительный класс.

Вторая функция возвращает AUC, полноту, точность и F-меру.

AUC — это площадь под кривой, построенной в осях точность-полнота.
Точность — это доля объектов на самом деле принадлежащих к положительному классу
среди всех объектов, которых модель отнесла к положительному классу.
\[
precision = TP / (TP + FP)
\]

А F-мера — это среднее гармоническое между точностью и полнотой.

Однако обе функции требуют, чтобы в данных были столбцы с вероятностями классов под названиями самих этих классов, истинные ответы под названием `ob`, и бинарные предсказания, названные как `pred`.
Поэтому создадим отдельную таблицу `ob_test_set` со всеми результатами оценивания.


```{r}
ob_test_set <- data.frame('0' = ob_prob$'0',
                        '1' = ob_prob$'1',
                        pred = ob_pred,
                        obs = ob_test$RPC)
glimpse(ob_test_set)
```


```{r}
prSummary(ob_test_set, lev = levels(ob_test_set$obs))
```

Почти все метрики можно визуализировать!
Но для примера мы построим ROC-кривую.
Для этого вдобавок к базовому cлою `ggplot` мы будем использовать слой `geom_roc` из пакета `plotROC`.
В эстетиках нужно указать аргументы `d` — истинные значения — и `m` — метки класса 1.
Если добавить аргумент `color`, то можно получить разные ROC-кривые по категориям какой-нибудь переменной.

```{r}
ggplot(ob_test_set, aes(d = obs, m = '1')) +
  geom_roc(n.cuts = '0')
```


```{r}
ob_test_set <- mutate(ob_test_set, RPC = ob_test$RPC)

ggplot(ob_test_set, aes(d = obs, m = '1', color = RPC)) +
  geom_roc(n.cuts = '0')
```



```{r}
ggplot(ob_test_set, aes(d = obs, m = '1')) +
  geom_roc(n.cuts = 0)

ob_test_set <- mutate(ob_test_set, RPC = ob_test$RPC)

ggplot(ob_test_set, aes(d = obs, m = '1', color = RPC)) +
  geom_roc(n.cuts = 0)
```


# На природу, к деревьям и в лес!

Бинарные деревья очень легко интепретируются при приемлемом качестве прогнозов.

Алгоритмы построения дерева отличаются деталями:

- по какому критерию делить веточку на две?
- когда остановить процесс деления веточек?
- следует ли обрезать дерево после окончания деления?
- как обрабатывать пропущенные значений?

```{r}
tree_model <- train(RPC ~ .- DOXODSN, data = ob_test,
                      method = 'rpart2',
                      na.action = na.omit)
```

Картинка дерева:

```{r}
rpart.plot(tree_model$finalModel)
```

Описание дерева:

```{r}
summary(tree_model)
```


Предсказываем с помощью дерева на тестовой выборке:

```{r}
ob_tree <- mutate(ob_test,
  yhat = predict(tree_model, ob_test, na.action = na.pass))
confusionMatrix(ob_tree$yhat, ob_tree$RPC)
```


# Случайный лес

В алгоритме случайного леса мы

1. Выращиваем целый лес, скажем 500, деревьев.

2. Строим прогноз с помощью каждого дерева.

3. Агрегируем прогнозы деревьев. Можно в качестве итогового прогноза выбрать ту категорию, за которую проголосовало большинство деревьев. Можно оценить вероятности категорий, взяв процент деревьев, проголосовавших за ту или иную категорию.

Деревья оказываются не идеальными копиями друг друга по двум причинам:

1. Каждое дерево обучается на случайной выборке из исходной выборки. Обычно для каждого дерева берут подвыборку с повторениями из исходной выборки, так чтобы размер подвыборки равнялся размеру исходной выборки.

2. При каждом делении каждой ветки на две части происходит предварительный случайный отбор переменных. Скажем, из исходных 100 переменных, каждый раз случайно отбирается 10, а затем из этих 10 выбирается наилучшая, по которой ветвь и делится на две ветви.

У идеи есть куча вариантов исполнения, отличающихся деталями:

- критерием деления ветви на две;
- критерием остановки деления дерева;
- количеством предварительно отбираемых переменных перед каждым делением;
- количество деревьев;


Посмотрим на все вариации случайного леса, которые перебрал `ranger`.

```{r}
ranger_model <- train(RPC ~ .- DOXODSN, data = ob_test,
                    method = 'ranger',
                    na.action = na.omit,
                    importance = 'impurity')
ranger_model
plot(ranger_model)
```

И более подробно про наилучшую:

```{r}
ranger_model$finalModel
```


К сожалению, построить информативно про все сотни деревьев невозможно.

Можно попытаться выделить важность переменных:

```{r}
ranger_import <- varImp(ranger_model)
ranger_import
plot(ranger_import)
```


И, конечно, построить прогнозы:

```{r}
ob_ranger <- mutate(ob_test,
  yhat = predict(ranger_model, ob_test, na.action = na.pass))
confusionMatrix(ob_ranger$yhat, ob_ranger$RPC)
```

По умолчанию, пакет `caret` сам решает, сколько значений параметров перебирать и какие конкретно.

Список перебираемых параметров:

```{r}
modelLookup(model = 'ranger')
```


Но мы можем заказать перебор любых.

Можно заказать количество перебираемых значений для каждого параметра:

```{r}
ranger_model <- train(RPC ~ ., data = ob_test,
                      method = "ranger",
                      na.action = na.omit,
                      importance = 'impurity',
                      tuneLength = 4)
```

Или явно значения

```{r}
grid <- expand.grid(mtry = c(5, 10), min.node.size = c(1, 5), splitrule = 'gini')

ranger_model <- train(RPC ~ ., data = ob_test,
            tuneGrid = grid, method = "ranger", na.action = na.omit)
ranger_model
```

:)
