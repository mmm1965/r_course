---
title: 'Семинар 7. Классификация'
date: 'Июнь, 19, 2018'
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: yes
lang: ru-RU
editor_options:
  chunk_output_type: console
---



Шаманское заклинание для настройки глобальных опций отчёта:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse) # обработка данных, графики...
library(skimr) # описательные статистики
library(rio) # импорт фантастического количества форматов данных
library(broom) # метла превращает результаты оценивания моделей в таблички
library(Ecdat) # много-много разных наборов данных
library(ISLR) # ещё данные
library(sandwich) # оценка Var для гетероскедастичности
library(caret) # пакет для подбора параметров разных моделей
library(FFTrees) # быстрые деревья
library(margins) # для подсчёта предельных эффектов
library(rpart.plot) # для картинок деревьев
library(plotROC) # визуализация ROC-кривой
library(ggeffects) # графики для предельных эффектов
library(MLmetrics) # метрики качества
```


Импортируем набор данных по респондентам и смотрим на него :)

```{r}
ob <- import('C:/Users/ASUS/Desktop/r_course/data/macro_3.sav')
skim(ob)
glimpse(ob)
```

Целевая переменная — Наличие персонального компьютера RPC (1-да, 0 – нет)
Остальные переменные — характеристики финансового положения респондента и условий его проживания.

```{r}
ob_fct <-ob %>%
 mutate_at(vars(LGDP), factor)
```


Разделим набор данных ob на обучающую и тестовую выборки так, чтобы в первую попало 75% всех наблюдений

```{r}
train_rows <- createDataPartition(ob_fct$LGDP, p = 0.75, list = FALSE)
ob_train <- ob[train_rows, ]
ob_test <- ob[-train_rows, ]
```

# Логистическая регрессия

С помощью метода максимального правдоподобия оценим модель
Реализуем логистическую регрессию с помощью функции glm. Передадим ей набор данных ob_train, формулу и укажем специалный аргумент family = binomial(link = 'logit'). Сохраним результаты оценивания в переменную ob_lmodel.
Построим модель зависимости уровня ВВВП на душу человека от одной переменной, отвечающей за качество жизни

```{r}
ob_lmodel_glm <- glm(data = ob_train, LGDP ~ Life, family = binomial(link = 'logit'))
summary(ob_lmodel_glm)
```
Переменная значимая, коэффициент Акаике = 26.005

Добавим вторую пеерменную, отвечающую за уровень безработицы в стране


```{r}
ob_lmodel_glm <- glm(data = ob_train, LGDP ~ Life + Unemployment, family = binomial(link = 'logit'))
summary(ob_lmodel_glm)
```
Переменные, вошедшие в модель, значимые, коэффициент Акаике уменьшился и составил = 13.375. Что свидетельствуюет о преимуществе модели с двумя коэффициетами по сравнению с первой моделью.

Отметим, что добавление новых пеерменных не приводило к улучшению характеристик модели, коэфииенты становились незначимые, AIC - существенно не уменьшался.


Чтобы найти предельные эффекты, воспользуемся функцией `margins` из одноимённого пакета.
Снова выведем результаты командой `summary()`.

```{r}
ob_margins <- margins(ob_lmodel_glm)
summary(ob_margins)
```

По умолчанию считается средний предельный эффект.
Если нужно подсчитать предельный эффект для конкретного наблюдения,
например, для среднего, то можно воспользоваться опцией `at`.

Предельные эффекты тоже можно визуализировать!
Эта функция реализована в пакете `ggeffects` и называетя `ggpredict`.
Ей нужно передать оценённую модель и указать переменные для визуализации в аргументе `terms`.

```{r, eval=FALSE}
pred_ob_vis <- ggpredict(ob_lmodel_glm, terms = c('LGDP'))
pred_ob_vis <- plot(pred_ob_vis)
```

Оценивать логистическую модель также можно с помощью пакета `caret`.
Изменения минимальные:

```{r}
ob_lmodel <- train(data = ob_train, LGDP ~ Life + Unemployment, family = binomial(link = 'logit'), method = 'glm')
summary(ob_lmodel)
```

Посторим прогнозы модели для тестовых данных `ob_test`.
Для этого будем использовать функцию `predict`, которой передадим оценённую модель `ob_lmodel`.
В переменной `ob_predz` уже будут лежать предсказанные классы.
Чтобы получить их вероятности, нужно добавить аргумент `type = 'prob'`.

```{r}
ob_pred <- predict(ob_lmodel, newdata = ob_test)
head(ob_pred)

ob_prob <- predict(ob_lmodel, newdata = ob_test, type = 'prob')
head(ob_prob)
```

Теперь мы можем посмотреть на матрицу ошибок и узнать, насколько хорошую модель мы оецнили.
Для этого будем использовть функцию `confusionMatrix` из пакета `caret`.
В качестве аргумента `data` нужно указать предсказанные значения, а в `reference` — правильные ответы.

```{r}
confusionMatrix(data = ob_pred, reference = ob_test$y)
```

* Упражнение 6.

Составьте матрицу ошибок для прогнозов модели `def_lmodel`.

```{r}
# confusionMatrix(data = ___, reference = ___)
```


Чтобы получичть и другие метрики качества для нашей модели, будем использовать функции `twoClassSummary()` и `prSummary()`.
Первая возвращает значения ROC, специфичности и чувствительности.

Чувствительность (полнота) показывает долю правильно распознанных объектов отрицательного класса.
\[
TPR = TP / (TP + FN) = recall = sensitivity
\]

Специфичность показывает долю правильно распознанных объектов положительного класса.
\[
FPR = FP / (FP + TN) = 1 - specificity
\]

ROC — это площадь под кривой, построенной в осях доли правильных положительных ответов и
доли неправильных положительных ответов в зависимости от значения порога для попадания
в положительный класс.

Вторая функция возвращает AUC, полноту, точность и F-меру.

AUC — это площадь под кривой, построенной в осях точность-полнота.
Точность — это доля объектов на самом деле принадлежащих к положительному классу
среди всех объектов, которых модель отнесла к положительному классу.
\[
precision = TP / (TP + FP)
\]

А F-мера — это среднее гармоническое между точностью и полнотой.

Однако обе функции требуют, чтобы во данных были столбцы с вероятностями классов под названиями самих этих классов, истинные ответы под названием `obs`, и бинарные предсказания, названные как `pred`.
Поэтому создадим отдельную таблицу `educ_test_set` со всеми результатами оценивания.

```{r}
educ_test_set <- data.frame(H = educ_prob$H,
                        L = educ_prob$L,
                        pred = educ_pred,
                        obs = educ_test$y)
glimpse(educ_test_set)

twoClassSummary(educ_test_set, lev = levels(educ_test_set$obs)) # don't work with tibble
prSummary(educ_test_set, lev = levels(educ_test_set$obs)) # нужен пакет MLmetrics
```

* Упражнение 7.

Выведите характеристики модели `def_lmodel` с помощью функций `twoClassSummary()` и `prSummary()`.

```{r}
# def_test_set <- data.frame(___ = def_prob$No,
#                            ___ = def_prob$Yes,
#                            pred = ___,
#                            obs = ___)

# twoClassSummary(___, lev = levels(def_test_set$obs))
# prSummary(___, lev = levels(___))
```


Почти все метрики можно визуализировать!
Но для примера мы построим ROC-кривую.
Для этого вдобавок к базовому cлою `ggplot` мы будем использовать слой `geom_roc` из пакета `plotROC`.
В эстетиках нужно указать аргументы `d` — истинные значения — и `m` — метки класса 1.
Если добавить аргумент `color`, то можно получить разные ROC-кривые по категориям какой-нибудь переменной.

```{r}
ggplot(educ_test_set, aes(d = obs, m = L)) +
  geom_roc(n.cuts = 0)

educ_test_set <- mutate(educ_test_set, gender = educ_test$gender)

ggplot(educ_test_set, aes(d = obs, m = L, color = gender)) +
  geom_roc(n.cuts = 0)
```

* Упражнение 8.

Визуализируйте ROC-кривую для прогнозов модели `def_lmodel`.
Сначала общую, а затем отдельно для студентов и всех остальных.

```{r}
# ggplot(___, aes(d = ___, m = Yes)) +
#   geom_roc(n.cuts = 0)

# def_test_set <- mutate(def_test_set, stud = ___)

# ggplot(___, aes(d = ___, m = Yes, color = ___)) +
#   geom_roc(___)
```



# На природу, к деревьям и в лес!

Бинарные деревья очень легко интепретируются при приемлемом качестве прогнозов.

Алгоритмы построения дерева отличаются деталями:

- по какому критерию делить веточку на две?
- когда остановить процесс деления веточек?
- следует ли обрезать дерево после окончания деления?
- как обрабатывать пропущенные значений?

```{r}
tree_model <- train(y ~ . - Class, data = educ_test,
                      method = 'rpart2',
                      na.action = na.omit)
```

Картинка дерева:

```{r}
rpart.plot(tree_model$finalModel)
```

Описание дерева:

```{r}
summary(tree_model)
```

* Упражнение 9.

Постройте дерево для набора данных `def`, визуализируйте результат и нарисуйте картинку.

```{r}
# def_tree <- train(data = ___, default ~ ., method = '___')
# rpart.plot(___$finalModel)
# summary(___)
```


Предсказываем с помощью дерева на тестовой выборке:

```{r}
educ_tree <- mutate(educ_test,
  yhat = predict(tree_model, educ_test, na.action = na.pass))
confusionMatrix(educ_tree$yhat, educ_tree$y)
```

* Упражнение 10.

Постройте прогнозы с помощью дерева на тестовой выборке `def_test` и
оцените его качество, посмотрев на матрицу ошибок.

```{r}
# def_tree_pred <- mutate(___,
#   yhat = predict(___, ___))
# confusionMatrix(___)s
```


Пакет `caret` представляет собой общий интерфейс ко многим моделям,
однако некоторые модели он ещё не поддерживает.
Например, быстрые и стройные, [fast and frugal](https://cran.r-project.org/web/packages/FFTrees/vignettes/FFTrees_heart.html), деревья.

Быстрые деревья нужны, например, в медицине, чтобы
создавать быстрые и простые рекомендации для спасения жизни.

Мы применим их для спасения неуспевающих студентов :)
Увы, пакет принимает на вход только 0/1 в зависимой переменной, поэтому заменим названия категорий на числа:

```{r}
educ_train2 <- mutate(educ_train, ybin = ifelse(y == 'H', 1, 0)) %>%
select(-Class)
```

И построим картинку для быстрого и стройного дерева:

```{r}
fftree_model <- FFTrees(formula = ybin ~ .,
                     data = educ_train2)
plot(fftree_model)
```

* Упражнение 11.

Используйте быстрые и стройные деревья для набора данных `def_train`.
Помните, что целевая переменная в нём закодирована как 'Yes' и 'No'.

```{r}
# def_train2 <- mutate(___, defaultbin = ifelse(default == ___))

# def_fftree <- FFTrees(formula = ___ ~ .,
#                       data = ___)
# plot(___)
```


# Случайный лес

В алгоритме случайного леса мы

1. Выращиваем целый лес, скажем 500, деревьев.

2. Строим прогноз с помощью каждого дерева.

3. Агрегируем прогнозы деревьев. Можно в качестве итогового прогноза выбрать ту категорию, за которую проголосовало большинство деревьев. Можно оценить вероятности категорий, взяв процент деревьев, проголосовавших за ту или иную категорию.

Деревья оказываются не идеальными копиями друг друга по двум причинам:

1. Каждое дерево обучается на случайной выборке из исходной выборки. Обычно для каждого дерева берут подвыборку с повторениями из исходной выборки, так чтобы размер подвыборки равнялся размеру исходной выборки.

2. При каждом делении каждой ветки на две части происходит предварительный случайный отбор переменных. Скажем, из исходных 100 переменных, каждый раз случайно отбирается 10, а затем из этих 10 выбирается наилучшая, по которой ветвь и делится на две ветви.

У идеи есть куча вариантов исполнения, отличающихся деталями:

- критерием деления ветви на две;
- критерием остановки деления дерева;
- количеством предварительно отбираемых переменных перед каждым делением;
- количество деревьев;


Посмотрим на все вариации случайного леса, которые перебрал `ranger`.

```{r}
ranger_model <- train(y ~ . - Class, data = educ_test,
                    method = 'ranger',
                    na.action = na.omit,
                    importance = 'impurity')
ranger_model
plot(ranger_model)
```

И более подробно про наилучшую:

```{r}
ranger_model$finalModel
```

* Упражнение 12.

Реализуйте случайный лес для данных про кредиты,
выведите описание лучешй модели и постройте визуализацию.

```{r}
# def_ranger <- train(___ ~ ., data = ___,
#                     method = '___',
#                     importance = 'impurity')
# def_ranger$___
# plot(___)
```


К сожалению, построить информативно про все сотни деревьев невозможно.

Можно попытаться выделить важность переменных:

```{r}
ranger_import <- varImp(ranger_model)
ranger_import
plot(ranger_import)
```


* Упражнение 13.

Выделите важность переменных в модели `def_ranger`.

```{r}
# def_import <- varImp(___)
# def_import
# plot(___)
```

И, конечно, построить прогнозы:

```{r}
educ_ranger <- mutate(educ_test,
  yhat = predict(ranger_model, educ_test, na.action = na.pass))
confusionMatrix(educ_ranger$yhat, educ_ranger$y)
```

По умолчанию, пакет `caret` сам решает, сколько значений параметров перебирать и какие конкретно.

Список перебираемых параметров:

```{r}
modelLookup(model = 'ranger')
```


Но мы можем заказать перебор любых.

Можно заказать количество перебираемых значений для каждого параметра:

```{r}
ranger_model <- train(y ~ . - Class, data = educ_test,
                      method = "ranger",
                      na.action = na.omit,
                      importance = 'impurity',
                      tuneLength = 4)
```

Или явно значения

```{r}
grid <- expand.grid(mtry = c(5, 10), min.node.size = c(1, 5), splitrule = 'gini')

ranger_model <- train(y ~ . - Class, data = educ_test,
            tuneGrid = grid, method = "ranger", na.action = na.omit)
ranger_model
```



Ура :)
